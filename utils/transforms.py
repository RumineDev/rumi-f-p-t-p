import albumentations as A
import numpy as np
import cv2

from albumentations.pytorch import ToTensorV2
from torchvision import transforms as transforms

def resize(im, img_size=640, square=False):
    if square:
        im = cv2.resize(im, (img_size, img_size))
    else:
        h0, w0 = im.shape[:2]
        r = img_size / max(h0, w0)
        if r != 1:
            im = cv2.resize(im, (int(w0 * r), int(h0 * r)))
    return im

# ULTIMATE FIX: Custom bbox params that DOESN'T validate
class SafeBboxParams(A.BboxParams):
    """BboxParams that clips instead of validating"""
    def __init__(self, *args, **kwargs):
        # Force check_validity to False
        kwargs['check_validity'] = False
        super().__init__(*args, **kwargs)

def clip_bboxes(bboxes, rows, cols):
    """Clip bboxes to valid range [0, 1] for normalized coords"""
    clipped = []
    for bbox in bboxes:
        x_min, y_min, x_max, y_max = bbox[:4]
        label = bbox[4] if len(bbox) > 4 else None
        
        # Clip to [0, 1] range
        x_min = max(0.0, min(x_min, 0.999))
        y_min = max(0.0, min(y_min, 0.999))
        x_max = max(0.001, min(x_max, 1.0))
        y_max = max(0.001, min(y_max, 1.0))
        
        # Ensure max > min
        if x_max <= x_min:
            x_max = min(x_min + 0.01, 1.0)
        if y_max <= y_min:
            y_max = min(y_min + 0.01, 1.0)
        
        if label is not None:
            clipped.append([x_min, y_min, x_max, y_max, label])
        else:
            clipped.append([x_min, y_min, x_max, y_max])
    
    return clipped

# Training augmentation WITHOUT validation
def get_train_aug():
    """
    Safe training augmentation - NO BBOX VALIDATION
    Clips bboxes instead of throwing errors
    """
    return A.Compose([
        A.HorizontalFlip(p=0.5),
        A.ShiftScaleRotate(
            shift_limit=0.03,
            scale_limit=0.08,
            rotate_limit=5,
            border_mode=cv2.BORDER_REFLECT_101,
            p=0.3
        ),
        # Removed RandomResizedCrop - too aggressive
        A.OneOf([
            A.MotionBlur(blur_limit=3, p=0.4),
            A.GaussianBlur(blur_limit=(3, 5), p=0.4),
            A.MedianBlur(blur_limit=3, p=0.2),
        ], p=0.4),
        A.OneOf([
            A.RandomBrightnessContrast(
                brightness_limit=0.20,
                contrast_limit=0.25,
                p=0.6
            ),
            A.ColorJitter(
                brightness=0.15,
                contrast=0.15,
                saturation=0.10,
                hue=0.015,
                p=0.4
            ),
        ], p=0.5),
        A.RandomFog(
            alpha_coef=0.04,
            fog_coef_lower=0.1,
            fog_coef_upper=0.3,
            p=0.15
        ),
        A.RandomGamma(
            gamma_limit=(85, 120),
            p=0.2
        ),
        ToTensorV2(p=1.0),
    ], bbox_params=SafeBboxParams(
        format='pascal_voc',
        label_fields=['labels'],
        min_visibility=0.1,  # Permissive
        min_area=1,          # Very permissive
        check_validity=False # CRITICAL: NO VALIDATION!
    ))


def get_train_transform():
    """Minimal transform - no augmentation"""
    return A.Compose([
        ToTensorV2(p=1.0),
    ], bbox_params=SafeBboxParams(
        format='pascal_voc',
        label_fields=['labels'],
        check_validity=False
    ))


def transform_mosaic(mosaic, boxes, img_size=640):
    """Mosaic transform with safe bbox handling"""
    aug = A.Compose([A.Resize(img_size, img_size, always_apply=True, p=1.0)])
    sample = aug(image=mosaic)
    resized_mosaic = sample['image']
    
    transformed_boxes = (np.array(boxes) / mosaic.shape[0]) * resized_mosaic.shape[1]
    
    # Clip boxes
    validated = []
    for box in transformed_boxes:
        xmin, ymin, xmax, ymax = box
        
        # Clip to bounds
        xmin = max(0, min(xmin, resized_mosaic.shape[1] - 2))
        ymin = max(0, min(ymin, resized_mosaic.shape[0] - 2))
        xmax = max(xmin + 2, min(xmax, resized_mosaic.shape[1]))
        ymax = max(ymin + 2, min(ymax, resized_mosaic.shape[0]))
        
        if xmax > xmin + 1 and ymax > ymin + 1:
            validated.append([xmin, ymin, xmax, ymax])
    
    return resized_mosaic, np.array(validated) if validated else np.array([])


def get_valid_transform():
    """Validation transform"""
    return A.Compose([
        ToTensorV2(p=1.0),
    ], bbox_params=SafeBboxParams(
        format='pascal_voc',
        label_fields=['labels'],
        check_validity=False
    ))


def infer_transforms(image):
    """Inference transform"""
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.ToTensor(),
    ])
    return transform(image)